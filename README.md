
---

### **Тестовое задание: C# Backend, обработка событий с использованием Kafka, PostgreSQL и IObserver**

#### **Цель**
Необходимо реализовать backend-сервис на **C# (.NET 9)**, который:
1. Подписывается на события из **Apache Kafka**.
2. Обрабатывает эти события, используя паттерн **Observer (IObservable / IObserver)**.
3. Сохраняет обработанные данные в базу данных (**PostgreSQL**) или файловую систему.

Это задание поможет оценить навыки работы с асинхронными потоками данных, Kafka, паттерном Observer.

---

### **Задачи**

#### **1. Kafka Consumer**
Создайте сервис, который:
1. Подключается к **Apache Kafka** и подписывается на топик `user-events`.
   - Топик содержит JSON-сообщения о действиях пользователей:
     ```json
     {
       "userId": 123,
       "eventType": "click",
       "timestamp": "2025-04-16T12:34:56Z",
       "data": {
         "buttonId": "submit"
       }
     }
     ```
2. Читает сообщения из Kafka и передает их в систему обработки (паттерн Observer).

---

#### **2. Реализация Observer**
Используйте паттерн **Observer** для обработки событий:
1. Создайте класс, реализующий интерфейс **IObservable<T>**, который будет уведомлять подписчиков о новых событиях.
2. Создайте класс, реализующий интерфейс **IObserver<T>**, который будет:
   - Фильтровать события по типу (`eventType`).
   - Считать количество событий для каждого пользователя.
   - Сохранять результаты в базу данных или файл.

Пример результата обработки:
```json
[
  {
    "userId": 123,
    "eventType": "click",
    "count": 5
  },
  {
    "userId": 456,
    "eventType": "hover",
    "count": 3
  }
]
```

---

#### **3. Сохранение данных**
Реализуйте сохранение обработанных данных:
1. Вариант 1: Сохраняйте данные в **PostgreSQL** таблицу `user_event_stats`.
   - Структура таблицы:
     ```sql
     CREATE TABLE user_event_stats (
       user_id INT NOT NULL,
       event_type VARCHAR(50) NOT NULL,
       count INT NOT NULL,
       PRIMARY KEY (user_id, event_type)
     );
     ```
2. Вариант 2: Сохраняйте данные в JSON-файл `user_event_stats.json`.

---

### **Детали реализации**

#### **1. Apache Kafka**
- Используйте библиотеку **Confluent.Kafka** для работы с Kafka.
- Настройки подключения к Kafka должны браться из переменных окружения:
  - `KAFKA_BOOTSTRAP_SERVERS`
  - `KAFKA_TOPIC`
  - `KAFKA_GROUP_ID`

#### **2. PostgreSQL**
- Для работы с PostgreSQL используйте библиотеку **Npgsql**.
- Настройки подключения к базе данных также берутся из переменных окружения:
  - `POSTGRES_CONNECTION_STRING`

#### **3. Технологии**
- Язык программирования: **C# (.NET 9)**.
- Рекомендуемые пакеты:
  - **Confluent.Kafka** для работы с Kafka.
  - **System.Reactive** для реализации паттерна Observer.
  - **Npgsql** для работы с PostgreSQL (если выбран этот вариант).

---

### **Структура проекта**
Ваш проект должен содержать следующие файлы:
1. **KafkaConsumer.cs** — реализация Kafka Consumer.
2. **EventObservable.cs** — реализация `IObservable<T>` для событий.
3. **EventObserver.cs** — реализация `IObserver<T>` для обработки событий.
4. **DataStorage.cs** — класс для сохранения данных в базу данных или файл.

Пример структуры:
```
/Services
  KafkaConsumer.cs
  EventObservable.cs
  EventObserver.cs
/Data
  DataStorage.cs
/appsettings.json (если нужно)
```

---

### **Критерии оценки**
1. **Чистота и читаемость кода**:
   - Код должен быть легко читаемым и понятным.
   - Используйте осмысленные имена переменных и методов.
2. **Корректность работы с Kafka**:
   - Убедитесь, что сервис корректно читает сообщения из Kafka.
   - Обработайте возможные ошибки (например, отсутствие подключения к Kafka).
3. **Реализация паттерна Observer**:
   - Проверьте, что паттерн реализован правильно и работает эффективно.
4. **Сохранение данных**:
   - Убедитесь, что данные сохраняются корректно (в базу данных или файл).

---

### **Дополнительные задания (необязательно)**
1. **Тестирование**:
   - Напишите простые unit-тесты для проверки основной логики (если есть время).
2. **Логирование**:
   - Добавьте базовое логирование (например, используя `Console.WriteLine`) для отслеживания работы сервиса.
3. **Бонус**:
   - Реализуйте возможность фильтрации событий по временному диапазону.

---

### **Пример использования**
1. Запуск сервиса:
   - Сервис начинает читать сообщения из Kafka.
   - Сообщения обрабатываются через паттерн Observer.
   - Результаты сохраняются в базу данных или файл.
2. Пример сохраненных данных (JSON):
   ```json
   [
     {
       "userId": 123,
       "eventType": "click",
       "count": 5
     },
     {
       "userId": 456,
       "eventType": "hover",
       "count": 3
     }
   ]
   ```

---



